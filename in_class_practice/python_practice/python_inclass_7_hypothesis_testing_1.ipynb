{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Class Practice #7-1: Hypothesis Testing\n",
    "\n",
    "Adapted from: Data Analysis in Water Sciences (Jessica Lundquist, Steven Pestana)\n",
    "\n",
    "The Niagara River in New York state appears to have had a change in streamflow around the year 1980. \n",
    "* Test for statistical significance of the observed change in the mean annual flood. \n",
    "* Use a two-sample test, with alpha=0.05 (i.e. 95% confidence) and the z-distribution to define the rejection region.\n",
    "\n",
    "Why is it appropriate to use the z-distribution here? (consider the [Central Limit Theorem](https://en.wikipedia.org/wiki/Central_limit_theorem))\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath to our excel file.\n",
    "flow_data_file = 'python_inclass_practice_7.data.csv'\n",
    "\n",
    "# Use pandas.read_excel() function to open this file.\n",
    "flow_data = pd.read_csv(flow_data_file,index_col=[0],parse_dates=True)\n",
    "\n",
    "# Now we can see the dataset we loaded:\n",
    "flow_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset contains data for both Niagara River and Cayuga Creek\n",
    "# Now that we only select Niagara data using\n",
    "niagara_id = \"04216000\"\n",
    "\n",
    "# Here we only focus on the data for Niagara River\n",
    "niagara_flow = flow_data[[niagara_id]].loc[slice(\"1944\",\"2021\")]\n",
    "niagara_flow = niagara_flow.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the annual maximum flow\n",
    "niagara_peak_flow = niagara_flow[[niagara_id]].groupby(niagara_flow.index.year).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niagara_peak_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the annual maximum flow for next exercise\n",
    "niagara_peak_flow.to_csv(\"niagara_river.peak_flow.cfs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot peak streamflows per water year\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "\n",
    "niagara_peak_flow.plot(ax=ax)\n",
    "ax.set_ylabel('streamflow (cfs)');\n",
    "ax.set_title('Niagara River, Annual Peak Streamflow, (Buffalo, NY)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Getting started with our hypothesis\n",
    "\n",
    "We are postulating that there was a change in peak flows around 1980. In other words, how likely is it that the mean of peak flows before 1980 comes from the same distribution as the mean of peak flows after 1980?\n",
    "\n",
    "To start, let's split the data in two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into the early period (before 1980) and late period (after and including 1980). \n",
    "\n",
    "niagara_before = niagara_peak_flow[ niagara_peak_flow.index < 1980 ]\n",
    "niagara_after = niagara_peak_flow[ niagara_peak_flow.index >= 1980 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot our two time periods\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "\n",
    "niagara_before.plot(ax=ax, linestyle='-', label='pre-1980')\n",
    "niagara_after.plot(ax=ax, linestyle='--', label='post-1980')\n",
    "\n",
    "ax.set_ylabel('streamflow (cfs)');\n",
    "ax.set_title('Niagara River, Annual Peak Streamflow, (Buffalo, NY)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does the distribution of streamflows in each period look like?**\n",
    "\n",
    "Plot a histogram for each period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10,3))\n",
    "\n",
    "ax1.hist(niagara_before[niagara_id], bins=10)\n",
    "# ax1.set_xlim((1e4,1.4e5))\n",
    "ax1.set_xlabel('peak value (cfs)')\n",
    "ax1.set_title('Niagara River, Annual Peak Streamflow\\nHistogram Before 1980')\n",
    "\n",
    "ax2.hist(niagara_after[niagara_id], bins=10)\n",
    "# ax2.set_xlim((1e4,1.4e5))\n",
    "ax2.set_xlabel('peak value (cfs)')\n",
    "ax2.set_title('Niagara River, Annual Peak Streamflow\\nHistogram After 1980');\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cumulative distribution functions\n",
    "\n",
    "Visually compare the distributions of the data, before and after 1980, with theoretical distributions, and random numbers generated from theoretical distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Method 1\n",
    "# This function requires that the input is a pandas dataframe, with column names, and an integer index\n",
    "# It returns a copy of the dataframe with an extra column added that has the Cunnane plotting positions\n",
    "def cunnane_quantile(df, column_name):\n",
    "    '''\n",
    "    This function will compute the Cunnane plotting position \n",
    "    for the values in a column of a dataframe.\n",
    "    It requres a pandas dataframe, and the column name of \n",
    "    interest (a text string) as inputs.\n",
    "    The output is a new dataframe, ranked (sorted) with an extra \n",
    "    column with the plotting position.\n",
    "    [Steven Pestana, spestana@uw.edu, Oct. 2020]\n",
    "    '''\n",
    "    \n",
    "    # Rank all our values\n",
    "    ranked_df = df.sort_values(by=[column_name]).reset_index()\n",
    "    \n",
    "    # Calculate the Cunnane plotting position\n",
    "    ranked_df['cunnane_plotting_position'] = ((ranked_df.index + 1) - (2/5)) / (ranked_df[column_name].count() + (1/5))\n",
    "        \n",
    "    return ranked_df\n",
    "\n",
    "### Method 2\n",
    "# This function should be able to accept any one-dimensional numpy array or list, of numbers\n",
    "# It returns two numpy arrays, one of the sorted numbers, the other of the plotting position\n",
    "def cunnane_quantile_array(numbers):\n",
    "    '''\n",
    "    This function also computes the Cunnane plotting position \n",
    "    given an array or list of numbers \n",
    "    (rather than a pandas dataframe).\n",
    "    It has two outputs, first the sorted numbers, \n",
    "    second the Cunnane plotting position for each of those numbers.\n",
    "    [Steven Pestana, spestana@uw.edu, Oct. 2020]\n",
    "    '''\n",
    "    \n",
    "    # 1) sort the data, using the numpy sort function (np.sort())\n",
    "    sorted_numbers = np.sort(numbers)\n",
    "    \n",
    "    # length of the list of numbers\n",
    "    n = len(sorted_numbers) \n",
    "    \n",
    "    # make an empty array, of the same length. below we will add the plotting position values to this array\n",
    "    cunnane_plotting_position = np.empty(n)\n",
    "    \n",
    "    # 2) compute the Cunnane plotting position for each number, using a for loop and the enumerate function\n",
    "    for rank, number in enumerate(sorted_numbers):\n",
    "        cunnane_plotting_position[rank] = ( (rank+1) - (2/5) ) / ( n + (1/5) )\n",
    "    \n",
    "    return sorted_numbers, cunnane_plotting_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the cunnane quantile function for before 1980\n",
    "niagara_before_b = cunnane_quantile(niagara_before, niagara_id)\n",
    "\n",
    "# Create theoretical normal CDF based on our sample values before 1980\n",
    "theoretical_cdf_b = stats.norm.cdf(niagara_before_b[niagara_id].values,\n",
    "                                 niagara_before_b[niagara_id].mean(),\n",
    "                                 niagara_before_b[niagara_id].std(ddof=1))\n",
    "\n",
    "# Generate random numbers from a theoretical normal CDF based on our samples before 1980\n",
    "random_normal_b = np.random.normal(niagara_before_b[niagara_id].mean(),\n",
    "                                 niagara_before_b[niagara_id].std(ddof=1),\n",
    "                                 size=niagara_before_b[niagara_id].count())\n",
    "\n",
    "# Compute the Cunnane plotting position for the random numbers\n",
    "random_sorted_b, random_quantiles_b  = cunnane_quantile_array(random_normal_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the cunnane quantile function for after 1980\n",
    "niagara_after_a = cunnane_quantile(niagara_after, niagara_id)\n",
    "\n",
    "# Create theoretical normal CDF based on our sample values before 1980\n",
    "theoretical_cdf_a = stats.norm.cdf(niagara_after_a[niagara_id].values,\n",
    "                                 niagara_after_a[niagara_id].mean(),\n",
    "                                 niagara_after_a[niagara_id].std(ddof=1))\n",
    "\n",
    "# Generate random numbers from a theoretical normal CDF based on our samples before 1980\n",
    "random_normal_a = np.random.normal(niagara_after_a[niagara_id].mean(),\n",
    "                                 niagara_after_a[niagara_id].std(ddof=1),\n",
    "                                 size=niagara_after_a[niagara_id].count())\n",
    "\n",
    "# Compute the Cunnane plotting position for the random numbers\n",
    "random_sorted_a, random_quantiles_a  = cunnane_quantile_array(random_normal_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax1, ax2] = plt.subplots(nrows=1, ncols=2, figsize=(12,4))\n",
    "\n",
    "# Before 1980\n",
    "# Empirical CDF\n",
    "ax1.plot(niagara_before_b[niagara_id], niagara_before_b['cunnane_plotting_position'], color='k', label='Empirical CDF')\n",
    "# Theorectical Normal CDF\n",
    "ax1.plot(niagara_before_b[niagara_id], theoretical_cdf_b, label='Theoretical Normal CDF')\n",
    "# Random numbers CDF from a theoretical normal distribution\n",
    "ax1.plot(random_sorted_b,random_quantiles_b,'-', label='Random Numbers CDF')\n",
    "# Add legend and labels\n",
    "ax1.legend()\n",
    "ax1.set_ylabel('Cumulative Frequency')\n",
    "ax1.set_xlabel('Peak Flow (cfs)')\n",
    "ax1.set_title('Niagara River, Annual Peak Streamflow CDF\\nBefore 1980')\n",
    "\n",
    "# After 1980\n",
    "# Empirical CDF\n",
    "ax2.plot(niagara_after_a[niagara_id], niagara_after_a['cunnane_plotting_position'], color='k', label='Empirical CDF')\n",
    "# Theorectical Normal CDF\n",
    "ax2.plot(niagara_after_a[niagara_id], theoretical_cdf_a, label='Theoretical Normal CDF')\n",
    "# Random numbers CDF from a theoretical normal distribution\n",
    "ax2.plot(random_sorted_a, random_quantiles_a,'-', label='Random Numbers CDF')\n",
    "# Add legend and labels\n",
    "ax2.legend()\n",
    "ax2.set_ylabel('Cumulative Frequency')\n",
    "ax2.set_xlabel('Peak Flow (cfs)')\n",
    "ax2.set_title('Niagara River, Annual Peak Streamflow CDF\\nAfter 1980')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the streamflow data look normally distributed? Maybe try changing the above code to compare the empirical CDFs against theoretical lognormal distributions. (Remember to transform the mean and standard deviations into \"log space\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Two-Sample One-sided Z-Test\n",
    "\n",
    "#### In class, we introduced One-Sample Two-sided Z-test. Here we introduce Two-Sample One-sized Z-Test.\n",
    "\n",
    "\n",
    "#### Returning to our question: We are postulating (making a hypothesis) that there was a change in the mean flood statistics after 1980, and we want to test whether this is true.  Where do we start?\n",
    "\n",
    "First we can formally state our null hypothesis, and our alternative hypothesis. We are also told to use a two sample test, and to set $\\alpha$ at 5%.\n",
    "\n",
    "Our **null hypothesis** is that the peak flows of the early period ($\\bar{X}_1$) are drawn from the same distribution as the peak flows of the later period ($\\bar{X}_2$) (therefore the distributions means of the two time periods are equal):\n",
    "\n",
    "$H_0: \\bar{X}_1 = \\bar{X}_2$\n",
    "\n",
    "Our **alternative hypothesis** is that the mean of the distribution for the later period is greater than that of the early period:\n",
    "\n",
    "$H_1: \\bar{X}_2 > \\bar{X}_1$\n",
    "\n",
    "We can also state these as:\n",
    "\n",
    "$H_0: \\bar{X}_1 - \\bar{X}_2 = \\mu_0$\n",
    "\n",
    "$H_1: \\bar{X}_1 - \\bar{X}_2 < \\mu_0$\n",
    "\n",
    "Where $\\mu_0$ is the hypothesized difference between the population means, and in this case $\\mu_0 = \\mu_1 - \\mu_2 = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I have written a \"[one-sided](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests)\" test here because we are testing only for a change in one direction (an increase). We think that either the mean flood increased or it didn't change; we do not think the mean flood decreased:\n",
    "* This might be chosen because we have some physical reason to think it increased (e.g. higher elevations in the watershed now get rainfall where it used to mostly get snow because of our warming climate).\n",
    "* Or this might be chosen because we have some practical reason for the test to matter in this particular direction (e.g. we will change flood zoning downstream and/or how we operate a reservoir if the mean flood has increased, but won't make a change if it decreased)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But which test should we use?  Is the z-distribution valid?\n",
    "\n",
    "First, we are using the [z-test](https://en.wikipedia.org/wiki/Z-test), which uses the standard normal distribution. From our work above, we know that our data are likely not neccesarily normally distributed. However, the [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem) tells us that, \"*If a sample of n values is extracted at random from a population with mean  μ and standard deviation σ, and n > 30, then the means of these samples are approximately normally distributed*\"\n",
    "\n",
    "We calculate our z-score as: $\\displaystyle Z = \\frac{ (\\bar{X}_2 - \\bar{X}_1) - \\mu _{0} } { s_{1,2} }$\n",
    "\n",
    "Where $s_{1,2}$ is the \"pooled standard deviation\", $s_1$, $s_2$ and $n_1$, $n_2$ are the two standard deviations and sample sizes respectively.\n",
    "\n",
    "$s_{1,2} = \\displaystyle\\sqrt{ \\displaystyle\\frac{s^2_1}{n_1} + \\displaystyle\\frac{s^2_2}{n_2} }$\n",
    "\n",
    "#### Remember, the means are normally distributed even if the data themselves are not normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what does the \"**Null Distribution** look like for one-sided test?\n",
    "\n",
    "And what do the \"rejection regions\" look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "# Create a null pdf\n",
    "x = np.linspace(-4, 4, num=160)\n",
    "ax.plot(x, stats.norm.pdf(x, 0, 1), label='Normal Distribution PDF')\n",
    "\n",
    "# Plot the null cdf\n",
    "ax.plot(x, stats.norm.cdf(x, 0, 1), linestyle='--', label='Normal Distribution CDF')\n",
    "\n",
    "# Plot the region that z_test would have to fall in in order for us to reject the null hypothesis\n",
    "conf = 0.95\n",
    "z_alpha = stats.norm.ppf(conf)\n",
    "shade = np.linspace(z_alpha, 4, 10)\n",
    "ax.fill_between(shade, stats.norm.pdf(shade, 0, 1) ,  color='k', alpha=0.5, label='reject region\\nfor alpha={}'.format(np.round(1-conf,2)))\n",
    "# Plot a line at z_alpha\n",
    "plt.axvline(z_alpha, color='black', label='$z_{a}$')\n",
    "# Plot a line at our 95% confidence\n",
    "plt.axhline(conf, color='black', linestyle='--', label='Confidence = {}%'.format(conf*100))\n",
    "\n",
    "\n",
    "# Add labels\n",
    "ax.set_ylim((0,1))\n",
    "plt.xlabel('Z', fontsize=15)\n",
    "plt.ylabel('PDF', fontsize=15)\n",
    "ax.legend(loc='center left', fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we have a large enough sample size (n>30)\n",
    "\n",
    "n = len(niagara_before[niagara_id])\n",
    "print(n)\n",
    "\n",
    "m = len(niagara_after[niagara_id])\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both are larger than 30, so we can go ahead and calculate the z-score for our test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want our alpha to be 0.05\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Practice #1: What is confidence level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf =  # Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, determine which value in the z-distribution corresponds to our 0.95 confidence in the CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_alpha = stats.norm.ppf(conf)\n",
    "print(\"z_alpha = {}\".format(z_alpha)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the pooled standard deviation, $s_{1,2} = \\displaystyle\\sqrt{ \\displaystyle\\frac{s^2_1}{n_1} + \\displaystyle\\frac{s^2_2}{n_2} }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the pooled standard deviation\n",
    "pooled_sd = np.sqrt( niagara_before[niagara_id].std(ddof=1)**2 / n + niagara_after[niagara_id].std(ddof=1)**2 / m )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compute our z-score as  $\\displaystyle Z = \\frac{ (\\bar{X}_2 - \\bar{X}_1) - \\mu _{0} } { s_{1,2} }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesizing no change\n",
    "mu_0 = 0\n",
    "\n",
    "# compute z-score\n",
    "zscore = (niagara_after[niagara_id].mean() - niagara_before[niagara_id].mean() - mu_0)/pooled_sd\n",
    "\n",
    "print(\"z-score = {}\".format( np.round(zscore,2) )) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute a p-value from this z-score by looking it up on the standard normal distribution CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue = 1 - stats.norm.cdf(zscore)\n",
    "print(\"p = {}\".format( np.round(pvalue,3) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the z-distribution, our z-score test result, and the $z_\\alpha$ that corresponds with our 95% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create z values between -4 and 4 to look at the middle portion of the z-distribution around 0\n",
    "# Scale our values by the pooled standard deviation (otherwise we'd be in generic z-distribution space)\n",
    "z = np.linspace(-4, 4, num=160) * pooled_sd\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10,7))\n",
    "# Plot the z-distribution here\n",
    "plt.plot(z, stats.norm.pdf(z, 0, pooled_sd), label='Null PDF: ($\\overline{X}_2 - \\overline{X}_1$) = 0')\n",
    "\n",
    "# Plot a line at our z-alpha value and shade the rejection region\n",
    "plt.axvline(z_alpha*pooled_sd, color='black', linestyle='-', label='$z_{a}$')\n",
    "shade = np.linspace(z_alpha*pooled_sd, np.max(z), 10)\n",
    "plt.fill_between(shade, stats.norm.pdf(shade, 0, pooled_sd) ,  color='k', alpha=0.5, \n",
    "                 label='rejection region\\nfor alpha={}'.format(np.round(1-conf,2)))\n",
    "\n",
    "\n",
    "plt.axvline(zscore*pooled_sd, color='red', linestyle='-', label='z-test')\n",
    "plt.xlabel('($\\overline{X}_2 - \\overline{X}_1$) [cfs]', fontsize=15)\n",
    "plt.ylabel('PDF', fontsize=15)\n",
    "plt.ticklabel_format(axis='x', style='sci', scilimits=(0,0))\n",
    "plt.ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "plt.ylim(0, 9e-5)\n",
    "plt.legend(loc='best', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice #2: \n",
    "\n",
    "What do these test results mean? \n",
    "\n",
    "What does it mean that our z-test value (red line) fell within our \"rejection region\" of the null hypothesis PDF?\n",
    "\n",
    "What does our p-value tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type your results in this block\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice #3: Does Peak Flow Change in Cayuga Creek before and after 1980?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset contains data for both Niagara River and Cayuga Creek\n",
    "# Now that we only select Niagara data using\n",
    "cayuga_id = \"04215000\"\n",
    "\n",
    "# Here we only focus on the data for Niagara River\n",
    "cayuga_flow = flow_data[[cayuga_id]].loc[slice(\"1944\",\"2021\")]\n",
    "cayuga_flow = cayuga_flow.dropna()\n",
    "\n",
    "# Calculate the annual maximum flow\n",
    "cayuga_peak_flow = cayuga_flow[[cayuga_id]].groupby(cayuga_flow.index.year).max()\n",
    "\n",
    "cayuga_peak_flow['year'] = cayuga_peak_flow.index # for plotting purpuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cayuga_before = cayuga_peak_flow[cayuga_peak_flow.index < 1980]\n",
    "cayuga_after = cayuga_peak_flow[cayuga_peak_flow.index >= 1980]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cayuga_peak_flow.plot(x='year',y=cayuga_id,kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we have a large enough sample size (n>30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesizing no change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the p-values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is there a significant change in peak flow for Cayuga Creek before/after 1980?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test a different hypothesis\n",
    "\n",
    "How would the estimate of p change if our **null hypothesis** is now that the difference in the means is equal to 5% of the mean of the before-1980 period, and the alternative hypothesis is that a change more than 5% of the before-1980 period mean has occurred?\n",
    "\n",
    "Therefore\n",
    "\n",
    "$H_0: \\bar{X}_1 - \\bar{X}_2 = 0.05 \\cdot \\bar{X}_1$\n",
    "\n",
    "$H_1: \\bar{X}_1 - \\bar{X}_2 < 0.05 \\cdot \\bar{X}_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute our z-score and p-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesizing a 5% change\n",
    "mu_0 = 0.05 * niagara_before[niagara_id].mean()\n",
    "\n",
    "# compute z-score\n",
    "zscore = (niagara_after[niagara_id].mean() - niagara_before[niagara_id].mean() - mu_0)/pooled_sd\n",
    "print(\"z-score = {}\".format( np.round(zscore,2) )) \n",
    "\n",
    "pvalue = 1 - stats.norm.cdf(zscore)\n",
    "print(\"p = {}\".format( np.round(pvalue,3) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create z values between -4 and 4 to look at the middle portion of the z-distribution around 0\n",
    "z = np.linspace(-4, 4, num=160)\n",
    "# Scale our values by the pooled standard deviation (otherwise we'd be in generic z-distribution space)\n",
    "z = [i * pooled_sd for i in z]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10,7))\n",
    "# Plot the z-distribution here\n",
    "plt.plot(z, stats.norm.pdf(z, 0, pooled_sd), label='Null PDF: ($\\overline{X}_2 - \\overline{X}_1$) = 0.05*$\\overline{X}_1$')\n",
    "\n",
    "# Plot a line at our z-alpha value and shade the rejection region\n",
    "plt.axvline(z_alpha*pooled_sd, color='black', linestyle='-', label='$z_{a}$')\n",
    "shade = np.linspace(z_alpha*pooled_sd, np.max(z), 10)\n",
    "plt.fill_between(shade, stats.norm.pdf(shade, 0, pooled_sd) ,  color='k', alpha=0.5, label='rejection region\\nfor alpha={}'.format(np.round(1-conf,2)))\n",
    "\n",
    "plt.axvline(zscore*pooled_sd, color='red', linestyle='-', label='z-test')\n",
    "plt.xlabel('($\\overline{X}_2 - \\overline{X}_1$) = 0.2*$\\overline{X}_1$ [cfs]', fontsize=15)\n",
    "plt.ylabel('PDF', fontsize=15)\n",
    "plt.ticklabel_format(axis='x', style='sci', scilimits=(0,0))\n",
    "plt.ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "plt.ylim(0, 9e-5)\n",
    "plt.legend(loc='upper left', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So what happened with this second test?\n",
    "\n",
    "We created a more stringent test.\n",
    "\n",
    "For example, say we will only recommend constructing taller levees along the river if the mean flood (defined by the annual peak flow) increased by more than 5%. While we can report that we are 95% sure that there is a change greater than 0 (our first test); we are **not** 95% sure that the change is greater than 5% of the early period mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
