{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f0861c-34d8-40a4-a5ac-dc7e076356c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e88d40-8c6f-442b-b9b1-22ceb1b5f2b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# A quick detour on 'f-strings'\n",
    "In python there is a really nice way to insert values \n",
    "from variables into a string variable. This task is \n",
    "referred to in programming as string formatting. In the\n",
    "past there were other ways to do this in python, but \n",
    "a few years ago they added this approach which is generally\n",
    "seen as the best way to do this. For an overview see this:\n",
    "https://realpython.com/python-f-strings/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c185e157-18a6-43b8-a03f-065446b3ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_numbers = np.random.random(5)\n",
    "print('The average of my random numbers is', np.mean(random_numbers))\n",
    "print(f'The average of my random numbers is {np.mean(random_numbers):0.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ad9ca4-ac60-4183-9e28-2e457cfae738",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Access streamflow data for Niagara River!\n",
    "With that out of the way let's start to work towards being able to grab data on the fly from the USGS website. And now we've defined the site id for the Verde River, as well as some start and end dates to get the data for. With those defined clearly it makes it much easier for someone else to understand what you are trying to do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d7d082-34e5-4c77-97b5-00f110d9f618",
   "metadata": {},
   "source": [
    "## 1. define site specific information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323a5942-5409-43e5-a449-09cd448b7161",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'site_no': '04216000',\n",
    "    'begin_date': '2022-09-01',\n",
    "    'end_date': '2023-09-01'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21cf100-c509-41e6-a346-35cbe7fca1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = urllib.parse.urlencode(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ca6373-f05d-48cc-8898-d5d451e03673",
   "metadata": {},
   "outputs": [],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aa8845-ec7f-4ccc-be75-e1a439a30e1e",
   "metadata": {},
   "source": [
    "## 2. Create the url and access the data using `urllib`\n",
    "\n",
    "Now we can use f-strings to insert these values into the query URL which will point to the same website that we saw in the lecture portion\n",
    "You can verify this by copying the URL into your web browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164664d5-d754-45da-940a-58c0708e564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "verde_url = (\n",
    "    f'https://waterdata.usgs.gov/nwis/dv?'\n",
    "    f'cb_00060=on&format=rdb&referred_module=sw&{query}'\n",
    ")\n",
    "print(verde_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eec37ea-f83b-4c9a-8b6f-37de10e64058",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Read the data using `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390b1efa-39df-44d3-be4a-7f5aacbd535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With that we need to download the data and get it into pandas.\n",
    "# To download the data we'll use the `urllib` module which is \n",
    "# built into the python \"standard library\" of stuff you get for\n",
    "# free when you install python. We use the `urllib.request.urlopen`\n",
    "# function which simply opens a connection to the url, just like \n",
    "# going to the url in your web browser. Then, we can put the `response`\n",
    "# into `pd.read_table`. There are a lot of other parameters going \n",
    "# into this function now, and this is very common for when you scrape\n",
    "# data directly from the internet because formats vary.\n",
    "\n",
    "response = urllib.request.urlopen(verde_url)\n",
    "\n",
    "# Anyways, let's walk through a few of them:\n",
    "#  - comment='#': Lines beginning with a '#' are comments that pandas should ignore\n",
    "#  - sep='\\s+': The data representing columns are separated by white space\n",
    "#  - names: The names of the columns. I set these because the USGS ones are trash\n",
    "#  - index_col=2: Set the 3rd column as the index (that is, \"date\")\n",
    "#  - parse_dates=True: Try to make dates the correct data type, didn't work here but a good idea\n",
    "#  - date_format='yyyy-mm-dd': Display the format of date\n",
    "#  - engine='python': Python engine is currently more feature-complete\n",
    "\n",
    "df = pd.read_table(\n",
    "    response,\n",
    "    comment='#',\n",
    "    sep='\\s+',\n",
    "    names=['agency', 'site', 'date', 'streamflow', 'quality_flag'],\n",
    "    index_col=2,\n",
    "    parse_dates=True,\n",
    "    date_format='yyyy-mm-dd',\n",
    "    engine='python'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f6963d-ae61-4e80-b102-1d777b463599",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d289e8-f1d7-4421-adf9-ddc0b136ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discard the first two rows\n",
    "df = df.iloc[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a151d0c-3602-42f2-87a1-dcc004fd6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now convert the streamflow data to floats and\n",
    "# the index to datetimes. When processing raw data\n",
    "# it's common to have to do some extra postprocessing\n",
    "df['streamflow'] = df['streamflow'].astype(np.float64)\n",
    "df.index = pd.DatetimeIndex(df.index)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a017576-cb28-4acf-be26-a1412b085cad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
